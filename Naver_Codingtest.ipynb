{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Naver_Codingtest.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6e8fbfaaed04458db1702e8df5bf760b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_92b8c0107dad4c78979e83ca2823da92",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e19475c8123c4d36a673a63e59984d3e",
              "IPY_MODEL_0a579a8f259c4d92bbcf3aaebc47d243"
            ]
          }
        },
        "92b8c0107dad4c78979e83ca2823da92": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e19475c8123c4d36a673a63e59984d3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_1ff58460ff9a455c9132d2f59dafb50e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 5539,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 5539,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_480afbae23344dcb9cd858e1cdef8e97"
          }
        },
        "0a579a8f259c4d92bbcf3aaebc47d243": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f474dd88957649aa9281d26be47a8620",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 5540/? [05:18&lt;00:00, 17.38it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8637e0ab0b4a47e5bc26906d5620fcd8"
          }
        },
        "1ff58460ff9a455c9132d2f59dafb50e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "480afbae23344dcb9cd858e1cdef8e97": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f474dd88957649aa9281d26be47a8620": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8637e0ab0b4a47e5bc26906d5620fcd8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ade56ce2786f4ea3b710d8e3f75190c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_cf3298cd3fa043e996b7d3e6db8e4526",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a2710eec555d441cbeb29cef0e3b1d3d",
              "IPY_MODEL_9c644c187a634b16a5216e38e758736a"
            ]
          }
        },
        "cf3298cd3fa043e996b7d3e6db8e4526": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a2710eec555d441cbeb29cef0e3b1d3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e9cd419fcea5416fb97332818332a6e1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1999,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1999,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f0beb45d2e5b46aca7f4498ed4c5883b"
          }
        },
        "9c644c187a634b16a5216e38e758736a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_64a58e31128f4d169fb91ee409833eaa",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 2000/? [00:46&lt;00:00, 42.80it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_58bc24fb410b4f17a3be1aae16235607"
          }
        },
        "e9cd419fcea5416fb97332818332a6e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f0beb45d2e5b46aca7f4498ed4c5883b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "64a58e31128f4d169fb91ee409833eaa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "58bc24fb410b4f17a3be1aae16235607": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3ad4408513274d23a4b516b48ab6bb54": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_efc118f5794b4c7685e04bad88ce7e7b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c8564c72a2a04e9b8a15a9f331e51e29",
              "IPY_MODEL_33a9485487df43a8888232e517559882"
            ]
          }
        },
        "efc118f5794b4c7685e04bad88ce7e7b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c8564c72a2a04e9b8a15a9f331e51e29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_8f4f6533d0c645a2ae6cb6641b30c0c3",
            "_dom_classes": [],
            "description": " 63%",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 5539,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 3490,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2e5591c7f99a4824b3306fb3f7813350"
          }
        },
        "33a9485487df43a8888232e517559882": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_0bed9f7fdbe24d8c8a2f81c95b3dc843",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 3490/5539 [03:25&lt;01:47, 19.09it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_162e98c1d38349cf9ce1b15f081bab92"
          }
        },
        "8f4f6533d0c645a2ae6cb6641b30c0c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2e5591c7f99a4824b3306fb3f7813350": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0bed9f7fdbe24d8c8a2f81c95b3dc843": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "162e98c1d38349cf9ce1b15f081bab92": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J9K7FcPOD_0h",
        "colab_type": "text"
      },
      "source": [
        "# Naver Coding Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RxAu8RqdFn0v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "2d91a450-6e2e-4f52-f754-095360c99237"
      },
      "source": [
        "!which python\n",
        "!python --version"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/bin/python\n",
            "Python 3.6.9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EV50OHYeQA_F",
        "colab_type": "text"
      },
      "source": [
        "## Adding Data\n",
        "\n",
        "\n",
        "\n",
        "*   Running **locally**: navigate here to folder that contains datasets, so that pandas.read_csv finds files\n",
        "*   **Google drive**: create a folder with the datasets in google drive and mount google drive here\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iHQ1JDtpQO3O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "1a40b677-f75f-40b6-bfc0-e551cb8579d9"
      },
      "source": [
        "# to mount google drive folder with data\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "dataset_folder = '/content/gdrive/My Drive/Naver'\n",
        "%cd $dataset_folder\n",
        "!ls\n",
        "# expected output:\n",
        "# /content/gdrive/My Drive/Naver\n",
        "# Naver_Codingtest.ipynb\ttest_source.txt  train_source.txt\n",
        "# README.md\t\ttest_target.txt  train_target.txt"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "/content/gdrive/My Drive/Naver\n",
            "Naver_Codingtest.ipynb\ttest_source.txt  train_source.txt   train_target.txt\n",
            "README.md\t\ttest_target.txt  train_target.gdoc  weights\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EpNyBXWbRVBt",
        "colab_type": "text"
      },
      "source": [
        "## Dependencies\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hkLwMHVrRdzH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1d7fde8b-120a-40e4-fd18-a17f20269514"
      },
      "source": [
        "# general\n",
        "import time\n",
        "import math\n",
        "import random\n",
        "from tqdm.notebook import tqdm\n",
        "import os\n",
        "\n",
        "#plotting\n",
        "import matplotlib.pyplot as plt\n",
        "plt.switch_backend('agg')\n",
        "%matplotlib inline\n",
        "import matplotlib.ticker as ticker\n",
        "import numpy as np\n",
        "\n",
        "# dataset\n",
        "import pandas as pd\n",
        "\n",
        "#training\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print('Running on', device)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running on cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pzQyJwojze6s",
        "colab_type": "text"
      },
      "source": [
        "## Dataset and Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-pzB_BLTrrR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "64978fb0-eb9c-413c-a92c-b93603d7cb53"
      },
      "source": [
        "# end-of-sentence token\n",
        "EOS_token = 659\n",
        "SOS_token = 660\n",
        "\n",
        "class Seq2SeqDataSet(Dataset):\n",
        "  def __init__(self, source_path, target_path):\n",
        "    self.source_path = source_path\n",
        "    self.target_path = target_path\n",
        "    self.source_df = pd.read_csv(source_path, sep='\\t', header=None, names=['sequence'])\n",
        "    self.target_df = pd.read_csv(target_path, sep='\\t', header=None, names=['sequence'])\n",
        "    # assert len(self.source_df) == len(self.target_df)\n",
        "\n",
        "  def __len__(self):\n",
        "    return min(len(self.source_df), len(self.target_df))\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    source_data = self.source_df.iloc[idx]\n",
        "    target_data = self.target_df.iloc[idx]\n",
        "    # split numbers to list and remove final space if present\n",
        "    source_seq = str(source_data.sequence).rstrip().split(\" \")\n",
        "    target_seq = str(target_data.sequence).rstrip().split(\" \")\n",
        "    # map list-elements to int\n",
        "    source_seq = list(map(int, source_seq))\n",
        "    target_seq = list(map(int, target_seq))\n",
        "    source_seq.append(EOS_token)\n",
        "    target_seq.append(EOS_token)\n",
        "    source_seq = torch.tensor(source_seq, dtype=torch.long, device=device).view(-1, 1)\n",
        "    target_seq = torch.tensor(target_seq, dtype=torch.long, device=device).view(-1, 1)\n",
        "\n",
        "    return {'source_sequence': source_seq,\n",
        "            'target_sequence': target_seq\n",
        "            }\n",
        "\n",
        "\n",
        "train_dataset = Seq2SeqDataSet('train_source.txt', 'train_target.txt')\n",
        "print('train dataset with %i samples created' % len(train_dataset))\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=1, shuffle=True)\n",
        "\n",
        "val_dataset = Seq2SeqDataSet('test_source.txt', 'test_target.txt')\n",
        "print('test dataset with %i samples created' % len(val_dataset))\n",
        "val_loader = DataLoader(dataset=val_dataset, batch_size=1, shuffle=True)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train dataset with 5540 samples created\n",
            "test dataset with 2000 samples created\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HizUK_F1fx2Y",
        "colab_type": "text"
      },
      "source": [
        "## Overview over Data\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eCgwPv9rVEqB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "076e41ae-9312-4a6a-cb23-c5815286a554"
      },
      "source": [
        "source_min = 100000\n",
        "source_max = -1\n",
        "target_min = 100000\n",
        "target_max = -1\n",
        "source_max_length = 0\n",
        "target_max_length = 0\n",
        "for idx, batch in enumerate(val_loader):\n",
        "  source_sequence = batch['source_sequence']\n",
        "  target_sequence = batch['target_sequence']\n",
        "  if source_sequence.shape[1] > source_max_length:\n",
        "    source_max_length = source_sequence.shape[1]\n",
        "  if target_sequence.shape[1] > target_max_length:\n",
        "    target_max_length = target_sequence.shape[1]\n",
        "  if torch.max(source_sequence) > source_max:\n",
        "    source_max = torch.max(source_sequence).item()\n",
        "  if torch.max(target_sequence) > target_max:\n",
        "    target_max = torch.max(target_sequence).item()\n",
        "  # exclude EOS_TOKEN\n",
        "  if torch.min(source_sequence[:,:-1,:]) < source_min:\n",
        "    source_min = torch.min(source_sequence[:,:-1,:]).item()\n",
        "  if torch.min(target_sequence[:,:-1,:]) < target_min:\n",
        "    target_min = torch.min(target_sequence[:,:-1,:]).item()\n",
        "\n",
        "max_length = max(source_max_length, target_max_length)\n",
        "print('source')\n",
        "print('max ',source_max, '\\nmin ',source_min, '\\nmax length ', source_max_length)\n",
        "print('target')\n",
        "print('max ',target_max, '\\nmin ',target_min, '\\nmax length ', target_max_length)\n",
        "# expected output for training dataset\n",
        "# source\n",
        "# max  619 \n",
        "# min  21 \n",
        "# max length  82\n",
        "# target\n",
        "# max  658 \n",
        "# min  0 \n",
        "# max length  48\n",
        "\n",
        "# maximum length of eval set\n",
        "max_length = 85"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "source\n",
            "max  659 \n",
            "min  21 \n",
            "max length  85\n",
            "target\n",
            "max  659 \n",
            "min  2 \n",
            "max length  55\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJUDIXxcxsT3",
        "colab_type": "text"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qvvFp2sj5Clw",
        "colab_type": "text"
      },
      "source": [
        "### Encoder RNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9QwHwCFvxq3i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class EncoderRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(EncoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        output = embedded\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zGylupAU5JI-",
        "colab_type": "text"
      },
      "source": [
        "### RNN Decoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KVgO4kkoy50C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size):\n",
        "        super(DecoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        output = self.embedding(input).view(1, 1, -1)\n",
        "        output = F.relu(output)\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        output = self.softmax(self.out(output[0]))\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J1BjKInt5Mff",
        "colab_type": "text"
      },
      "source": [
        "### Attentional Decoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M9NKiamy5Osf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AttnDecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=max_length):\n",
        "        super(AttnDecoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.dropout_p = dropout_p\n",
        "        self.max_length = max_length\n",
        "\n",
        "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
        "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
        "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
        "        self.dropout = nn.Dropout(self.dropout_p)\n",
        "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
        "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
        "\n",
        "    def forward(self, input, hidden, encoder_outputs):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        embedded = self.dropout(embedded)\n",
        "\n",
        "        attn_weights = F.softmax(\n",
        "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
        "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
        "                                 encoder_outputs.unsqueeze(0))\n",
        "\n",
        "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
        "        output = self.attn_combine(output).unsqueeze(0)\n",
        "\n",
        "        output = F.relu(output)\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "\n",
        "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
        "        return output, hidden, attn_weights\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "luHcVgSNzCbA",
        "colab_type": "text"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GwkdVGNqzDnT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, \n",
        "          decoder_optimizer, criterion, teacher_forcing_ratio, max_length=max_length):\n",
        "  encoder_hidden = encoder.initHidden()\n",
        "  encoder_optimizer.zero_grad()\n",
        "  decoder_optimizer.zero_grad()\n",
        "  input_length = input_tensor.size(0)\n",
        "  target_length = target_tensor.size(0)\n",
        "\n",
        "  encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "  loss = 0\n",
        "\n",
        "  for elem in range(input_length):\n",
        "    encoder_output, encoder_hidden = encoder(\n",
        "      input_tensor[elem], encoder_hidden)\n",
        "    encoder_outputs[elem] = encoder_output[0, 0]\n",
        "  decoder_input = torch.tensor([[SOS_token]], device=device)\n",
        "\n",
        "  decoder_hidden = encoder_hidden\n",
        "\n",
        "  use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
        "\n",
        "  if use_teacher_forcing:\n",
        "    # Teacher forcing: Feed the target as the next input\n",
        "    for di in range(target_length):\n",
        "      decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "          decoder_input, decoder_hidden, encoder_outputs)\n",
        "      loss += criterion(decoder_output, target_tensor[di])\n",
        "      decoder_input = target_tensor[di]  # Teacher forcing\n",
        "\n",
        "  else:\n",
        "    # Without teacher forcing: use its own predictions as the next input\n",
        "    for di in range(target_length):\n",
        "      decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "          decoder_input, decoder_hidden, encoder_outputs)\n",
        "      topv, topi = decoder_output.topk(1)\n",
        "      decoder_input = topi.squeeze().detach()  # detach from history as input\n",
        "\n",
        "      loss += criterion(decoder_output, target_tensor[di])\n",
        "      if decoder_input.item() == EOS_token:\n",
        "        break\n",
        "\n",
        "  loss.backward()\n",
        "\n",
        "  encoder_optimizer.step()\n",
        "  decoder_optimizer.step()\n",
        "\n",
        "  return loss.item() / target_length"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6DicTeTB4g_-",
        "colab_type": "text"
      },
      "source": [
        "### Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SDSDlcW_4JSF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def asMinutes(s):\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)\n",
        "\n",
        "\n",
        "def timeSince(since, percent):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    es = s / (percent)\n",
        "    rs = es - s\n",
        "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T3GmEeA24Oyk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_epoch(encoder, decoder, \n",
        "                enc_optimizer, dec_optimizer,\n",
        "                train_loader, device, teacher_forcing_ratio, print_every=500, \n",
        "               plot_every=100):\n",
        "  start = time.time()\n",
        "  plot_losses = []\n",
        "  print_loss_total = 0  # Reset every print_every\n",
        "  plot_loss_total = 0  # Reset every plot_every\n",
        "\n",
        "\n",
        "  # training_pairs = [tensorsFromPair(random.choice(pairs))\n",
        "                    # for i in range(n_iters)]\n",
        "  n_iters = len(train_loader)\n",
        "  criterion = nn.NLLLoss()\n",
        "  progress_bar = tqdm(enumerate(train_loader), total=len(train_loader) - 1)\n",
        "\n",
        "  for iter, batch in progress_bar:\n",
        "    training_pair = batch\n",
        "    input_tensor = batch['source_sequence'].squeeze(0).to(device)\n",
        "    target_tensor = batch['target_sequence'].squeeze(0).to(device)\n",
        "\n",
        "    loss = train(input_tensor, target_tensor, encoder, decoder, \n",
        "                 enc_optimizer, dec_optimizer, criterion, teacher_forcing_ratio)\n",
        "    print_loss_total += loss\n",
        "    plot_loss_total += loss\n",
        "\n",
        "    if (iter + 1) % print_every == 0:\n",
        "      print_loss_avg = print_loss_total / print_every\n",
        "      print_loss_total = 0\n",
        "      print('\\n%s (%d %d%%) %.4f' % (timeSince(start, (iter+1) / n_iters),\n",
        "                                  (1+iter), (1+iter) / n_iters * 100, print_loss_avg))\n",
        "\n",
        "    if (iter + 1) % plot_every == 0:\n",
        "      plot_loss_avg = plot_loss_total / plot_every\n",
        "      plot_losses.append(plot_loss_avg)\n",
        "      plot_loss_total = 0\n",
        "\n",
        "  showPlot(plot_losses)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ed8mBk9g4mGw",
        "colab_type": "text"
      },
      "source": [
        "### Plotting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "isYxNwWT4n0j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def showPlot(points):\n",
        "    plt.figure()\n",
        "    fig, ax = plt.subplots()\n",
        "    # this locator puts ticks at regular intervals\n",
        "    loc = ticker.MultipleLocator(base=0.2)\n",
        "    ax.yaxis.set_major_locator(loc)\n",
        "    plt.plot(points)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VKZ7msVC4uPj",
        "colab_type": "text"
      },
      "source": [
        "## Evaluation function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uBMNOaty4vxw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(encoder, decoder, source_tensor, target_tensor, criterion, max_length=max_length):\n",
        "  with torch.no_grad():\n",
        "    loss = 0\n",
        "    input_length = source_tensor.size()[0]\n",
        "    target_length = target_tensor.size()[0]\n",
        "    encoder_hidden = encoder.initHidden()\n",
        "\n",
        "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "    for ei in range(input_length):\n",
        "      encoder_output, encoder_hidden = encoder(source_tensor[ei],\n",
        "                                                encoder_hidden)\n",
        "      encoder_outputs[ei] += encoder_output[0, 0]\n",
        "\n",
        "    decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
        "\n",
        "    decoder_hidden = encoder_hidden\n",
        "\n",
        "    decoded_words = []\n",
        "    decoder_attentions = torch.zeros(max_length, max_length)\n",
        "\n",
        "    for di in range(target_length):\n",
        "      decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "          decoder_input, decoder_hidden, encoder_outputs)\n",
        "      decoder_attentions[di] = decoder_attention.data\n",
        "      topv, topi = decoder_output.data.topk(1)\n",
        "      loss += criterion(decoder_output, target_tensor[di])\n",
        "      if topi.item() == EOS_token:\n",
        "          decoded_words.append('<EOS>')\n",
        "          break\n",
        "      else:\n",
        "          decoded_words.append(str(topi.item()))\n",
        "\n",
        "      decoder_input = topi.squeeze().detach()\n",
        "    return decoded_words, decoder_attentions[:di + 1], loss.item() / target_length"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VgwjSvFwuWUp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def eval_epoch(encoder, decoder, val_loader, device):\n",
        "  start = time.time()\n",
        "  loss_total = 0\n",
        "\n",
        "  n_iters = len(val_loader)\n",
        "  criterion = nn.NLLLoss()\n",
        "  progress_bar = tqdm(enumerate(val_loader), total=len(val_loader) - 1)\n",
        "\n",
        "  for iter, batch in progress_bar:\n",
        "    source_tensor = batch['source_sequence'].squeeze(0).to(device)\n",
        "    target_tensor = batch['target_sequence'].squeeze(0).to(device)\n",
        "\n",
        "    output, _, loss = evaluate(encoder, decoder, source_tensor, target_tensor, criterion)\n",
        "    loss_total += loss\n",
        "  print(loss_total) / len(val_loader))\n",
        "  return loss_total / len(val_loader)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B6jaYXzvz6KN",
        "colab_type": "text"
      },
      "source": [
        "## Run train and eval\n",
        "\n",
        "```\n",
        "load_pretrained = True\n",
        "```\n",
        "to load model state_dict and optimizer state from save_path/filename"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ky7G466n0un7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "load_pretrained = True\n",
        "save_path = '/content/gdrive/My Drive/Naver/weights'\n",
        "filename = 'attn_decoder_5epochs.pth'"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tcTvtkCs04Ux",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "56c70dc5-7311-46bf-a84a-1fca430ff209"
      },
      "source": [
        "### Hyper Parameters ###\n",
        "hidden_size = 256\n",
        "alphabet_size = 661\n",
        "dropout_prob = 0.1\n",
        "learning_rate = 0.01\n",
        "teacher_forcing_ratio = 0.5\n",
        "\n",
        "# initialize model\n",
        "encoder = EncoderRNN(alphabet_size, hidden_size)\n",
        "attn_decoder = AttnDecoderRNN(hidden_size, alphabet_size, dropout_p=dropout_prob)\n",
        "\n",
        "# optimizer\n",
        "enc_optim = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
        "dec_optim = optim.SGD(attn_decoder.parameters(), lr=learning_rate)\n",
        "\n",
        "start_epoch = 0\n",
        "eval_avg_loss = []\n",
        "\n",
        "# continue training\n",
        "if load_pretrained:\n",
        "  if os.path.isfile(os.path.join(save_path, filename)):\n",
        "    print(\"=> loading checkpoint '{}'\".format(filename))\n",
        "    checkpoint = torch.load(os.path.join(save_path, filename))\n",
        "    encoder.load_state_dict(checkpoint['state_dict_encoder'])\n",
        "    attn_decoder.load_state_dict(checkpoint['state_dict_decoder'])\n",
        "    enc_optim.load_state_dict(checkpoint['optimizer_encoder'])\n",
        "    dec_optim.load_state_dict(checkpoint['optimizer_decoder'])\n",
        "    start_epoch = checkpoint['epoch']\n",
        "    eval_avg_loss = checkpoint['eval_avg_loss']\n",
        "    print(\"=> loaded checkpoint '{}' (epoch {})\"\n",
        "              .format(filename, checkpoint['epoch']))\n",
        "  else:\n",
        "    print(\"=> no checkpoint found at '{}'\".format(os.path.join(save_path, filename)))\n",
        "\n",
        "\n",
        "  \n",
        "encoder.to(device)\n",
        "attn_decoder.to(device)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "=> loading checkpoint 'attn_decoder_5epochs.pth'\n",
            "=> loaded checkpoint 'attn_decoder_5epochs.pth' (epoch 5)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AttnDecoderRNN(\n",
              "  (embedding): Embedding(661, 256)\n",
              "  (attn): Linear(in_features=512, out_features=85, bias=True)\n",
              "  (attn_combine): Linear(in_features=512, out_features=256, bias=True)\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (gru): GRU(256, 256)\n",
              "  (out): Linear(in_features=256, out_features=661, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YlriF3mk47_V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 759,
          "referenced_widgets": [
            "6e8fbfaaed04458db1702e8df5bf760b",
            "92b8c0107dad4c78979e83ca2823da92",
            "e19475c8123c4d36a673a63e59984d3e",
            "0a579a8f259c4d92bbcf3aaebc47d243",
            "1ff58460ff9a455c9132d2f59dafb50e",
            "480afbae23344dcb9cd858e1cdef8e97",
            "f474dd88957649aa9281d26be47a8620",
            "8637e0ab0b4a47e5bc26906d5620fcd8",
            "ade56ce2786f4ea3b710d8e3f75190c3",
            "cf3298cd3fa043e996b7d3e6db8e4526",
            "a2710eec555d441cbeb29cef0e3b1d3d",
            "9c644c187a634b16a5216e38e758736a",
            "e9cd419fcea5416fb97332818332a6e1",
            "f0beb45d2e5b46aca7f4498ed4c5883b",
            "64a58e31128f4d169fb91ee409833eaa",
            "58bc24fb410b4f17a3be1aae16235607",
            "3ad4408513274d23a4b516b48ab6bb54",
            "efc118f5794b4c7685e04bad88ce7e7b",
            "c8564c72a2a04e9b8a15a9f331e51e29",
            "33a9485487df43a8888232e517559882",
            "8f4f6533d0c645a2ae6cb6641b30c0c3",
            "2e5591c7f99a4824b3306fb3f7813350",
            "0bed9f7fdbe24d8c8a2f81c95b3dc843",
            "162e98c1d38349cf9ce1b15f081bab92"
          ]
        },
        "outputId": "08828c11-5be6-407d-80ef-8e57cbb1af57"
      },
      "source": [
        "number_of_epochs = 2\n",
        "\n",
        "for epoch in range(start_epoch, start_epoch + number_of_epochs):\n",
        "  print('Starting epoch {}:'.format(epoch+1))\n",
        "  train_epoch(encoder, attn_decoder, enc_optim, dec_optim, train_loader, device,\n",
        "              teacher_forcing_ratio)\n",
        "  avg_loss = eval_epoch(encoder, attn_decoder, val_loader, device)\n",
        "  eval_avg_loss.append(avg_loss)\n",
        "\n",
        "showPlot(eval_avg_loss)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting epoch 6:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6e8fbfaaed04458db1702e8df5bf760b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=5539.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "0m 28s (- 4m 51s) (500 9%) 1.4840\n",
            "\n",
            "0m 57s (- 4m 21s) (1000 18%) 1.4306\n",
            "\n",
            "1m 25s (- 3m 51s) (1500 27%) 1.4773\n",
            "\n",
            "1m 54s (- 3m 22s) (2000 36%) 1.4468\n",
            "\n",
            "2m 23s (- 2m 53s) (2500 45%) 1.3550\n",
            "\n",
            "2m 50s (- 2m 24s) (3000 54%) 1.3832\n",
            "\n",
            "3m 18s (- 1m 55s) (3500 63%) 1.4179\n",
            "\n",
            "3m 47s (- 1m 27s) (4000 72%) 1.4258\n",
            "\n",
            "4m 17s (- 0m 59s) (4500 81%) 1.4687\n",
            "\n",
            "4m 46s (- 0m 30s) (5000 90%) 1.5187\n",
            "\n",
            "5m 16s (- 0m 2s) (5500 99%) 1.4145\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ade56ce2786f4ea3b710d8e3f75190c3",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=1999.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Starting epoch 7:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3ad4408513274d23a4b516b48ab6bb54",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=5539.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "0m 28s (- 4m 42s) (500 9%) 1.1870\n",
            "\n",
            "0m 57s (- 4m 21s) (1000 18%) 1.2161\n",
            "\n",
            "1m 28s (- 3m 58s) (1500 27%) 1.2326\n",
            "\n",
            "1m 57s (- 3m 27s) (2000 36%) 1.3212\n",
            "\n",
            "2m 26s (- 2m 58s) (2500 45%) 1.3265\n",
            "\n",
            "2m 56s (- 2m 29s) (3000 54%) 1.3113\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1JWeOG08x4KX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "save_path = '/content/gdrive/My Drive/Naver/weights'\n",
        "filename = 'attn_decoder_7epochs.pth'\n",
        "def save_checkpoint(state, save_path, filename):\n",
        "    torch.save(state, os.path.join(save_path,filename))\n",
        "\n",
        "\n",
        "save_checkpoint({'epoch': epoch + 1,\n",
        "                  'state_dict_encoder': encoder.state_dict(),\n",
        "                  'state_dict_decoder': attn_decoder.state_dict(),\n",
        "                  'optimizer_encoder': enc_optim.state_dict(),\n",
        "                  'optimizer_decoder': dec_optim.state_dict(),\n",
        "                  'eval_avg_loss': eval_avg_loss},\n",
        "                save_path,\n",
        "                filename)\n",
        "print('saved model to', os.path.join(save_path, filename))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0BMXNvf4URAN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate_sample(encoder, decoder, source_tensor, max_length=max_length):\n",
        "    with torch.no_grad():\n",
        "        input_length = source_tensor.size()[0]\n",
        "        encoder_hidden = encoder.initHidden()\n",
        "\n",
        "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "        for ei in range(input_length):\n",
        "            encoder_output, encoder_hidden = encoder(source_tensor[ei],\n",
        "                                                     encoder_hidden)\n",
        "            encoder_outputs[ei] += encoder_output[0, 0]\n",
        "\n",
        "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
        "\n",
        "        decoder_hidden = encoder_hidden\n",
        "\n",
        "        decoded_words = []\n",
        "        decoder_attentions = torch.zeros(max_length, max_length)\n",
        "\n",
        "        for di in range(max_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            decoder_attentions[di] = decoder_attention.data\n",
        "            topv, topi = decoder_output.data.topk(1)\n",
        "            if topi.item() == EOS_token:\n",
        "                decoded_words.append('<EOS>')\n",
        "                break\n",
        "            else:\n",
        "                decoded_words.append(str(topi.item()))\n",
        "\n",
        "            decoder_input = topi.squeeze().detach()\n",
        "\n",
        "        return decoded_words, decoder_attentions[:di + 1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XojSmWryqO6N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluateRandomly(encoder, decoder, n=10):\n",
        "    for i in range(n):\n",
        "        pair = random.choice(val_dataset)\n",
        "        print('source', pair['source_sequence'].cpu().numpy().squeeze(1).tolist())\n",
        "        print('target', pair['target_sequence'].cpu().numpy().squeeze(1).tolist())\n",
        "        output_words, attentions = evaluate_sample(encoder, decoder, pair['source_sequence'])\n",
        "        output_sentence = ' '.join(output_words)\n",
        "        print(' model', output_sentence)\n",
        "        print('')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "En5sp4iGqWIp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "evaluateRandomly(encoder, attn_decoder)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}